{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始之前，先明确一下我们的目标是什么，同时对提供的信息做一些简单的分析  \n",
    "> Competition Description  \n",
    "> ...  \n",
    "> **One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. **...      \n",
    ">  In this challenge, **we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.**  \n",
    "\n",
    "根据 Competition Description 我们可以得到哪些结论呢?  \n",
    "1. 造成大规模死亡很大的原因是因为没有足够的救生艇  \n",
    "2. 本次的目标是根据船上乘客/船员的特征判断是否能够生存  \n",
    "\n",
    "OK，接下来让我们看一下数据集中有哪些有用的信息  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，让我们看一下数据中有哪些属性，以及这些属性可能的值有哪些  \n",
    "下面的表格我们可以从[这里](https://www.kaggle.com/c/titanic/data)得到  \n",
    "\n",
    "| variables | definition | key |  \n",
    "|-----------|------------|-----|\n",
    "| Survival | 是否生存| 0 = No, 1 = Yes |  \n",
    "| Pclass  | 社会地位 | 1 = 1st, 2 = 2nd, 3 = 3rd |  \n",
    "| Sex\t| 性别 |  |  \n",
    "| Age\t| 年龄 |  |  \n",
    "| SibSp | 船上兄弟姐妹及配偶的数目\t|  |  \n",
    "| Parch | 船上父母的数目及子辈的数目 |  |  \n",
    "| Ticket | 票号 | |  \n",
    "| Fare | 费用 | |  \n",
    "| Cabin | 船舱号 | |  \n",
    "| Embarked | 上船的位置 | C = Cherbourg, Q = Queenstown, S = Southampton |  \n",
    "\n",
    "从上面的表格中我们可以知道每个数据属性的具体含义，这个时候我们可以做出以下不负责任的假设了 ~  \n",
    "1. Pclass 越高 Survival 的可能性越大  \n",
    "2. Sex 为 female 的 Survival 的可能性越大  \n",
    "3. Age 处在`儿童`以及`老人`阶段的 Survival 的可能性越大  \n",
    "4. SibSp 越大的 Survival 的可能性越小  \n",
    "5. Parch 越大的 Survival 的可能性越小  \n",
    "6. Fare 越高的 Survial 的可能性越小  \n",
    "7. Cabin 代表的客舱位置越高的 Survival 的可能性越小  \n",
    "8. Embarked 感觉上和 Survival 可能性应该没什么关系  \n",
    "\n",
    "接下来，我们导入数据集并看看数据集长什么样子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:  (891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Smith, Miss. Marion Elsie</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31418</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hagland, Mr. Ingvald Olai Olsen</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65303</td>\n",
       "      <td>19.9667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>536</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hart, Miss. Eva Miriam</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>F.C.C. 13529</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Salkjelsvik, Miss. Anna Kristine</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343120</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chapman, Mr. John Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/AH 29037</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Peuchen, Major. Arthur Godfrey</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113786</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>C104</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>678</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Turja, Miss. Anna Sofia</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4138</td>\n",
       "      <td>9.8417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vande Walle, Mr. Nestor Cyriel</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345770</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>West, Miss. Constance Mirium</td>\n",
       "      <td>female</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 34651</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                              Name     Sex  \\\n",
       "346          347         1       2         Smith, Miss. Marion Elsie  female   \n",
       "451          452         0       3   Hagland, Mr. Ingvald Olai Olsen    male   \n",
       "535          536         1       2            Hart, Miss. Eva Miriam  female   \n",
       "106          107         1       3  Salkjelsvik, Miss. Anna Kristine  female   \n",
       "594          595         0       2           Chapman, Mr. John Henry    male   \n",
       "884          885         0       3            Sutehall, Mr. Henry Jr    male   \n",
       "449          450         1       1    Peuchen, Major. Arthur Godfrey    male   \n",
       "677          678         1       3           Turja, Miss. Anna Sofia  female   \n",
       "200          201         0       3    Vande Walle, Mr. Nestor Cyriel    male   \n",
       "58            59         1       2      West, Miss. Constance Mirium  female   \n",
       "\n",
       "      Age  SibSp  Parch           Ticket     Fare Cabin Embarked  \n",
       "346  40.0      0      0            31418  13.0000   NaN        S  \n",
       "451   NaN      1      0            65303  19.9667   NaN        S  \n",
       "535   7.0      0      2     F.C.C. 13529  26.2500   NaN        S  \n",
       "106  21.0      0      0           343120   7.6500   NaN        S  \n",
       "594  37.0      1      0      SC/AH 29037  26.0000   NaN        S  \n",
       "884  25.0      0      0  SOTON/OQ 392076   7.0500   NaN        S  \n",
       "449  52.0      0      0           113786  30.5000  C104        S  \n",
       "677  18.0      0      0             4138   9.8417   NaN        S  \n",
       "200  28.0      0      0           345770   9.5000   NaN        S  \n",
       "58    5.0      1      2       C.A. 34651  27.7500   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "data_train = pd.read_csv('../input/train.csv')\n",
    "data_test = pd.read_csv('../input/test.csv')\n",
    "print('training data shape: ', data_train.shape)\n",
    "data_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "啊咧咧，看着这个表格，我们能得到很多关于数据的信息  \n",
    "1. Name 我们无法直接利用，但是 Name 格式是 ?Name + 称谓 + ?Name 的形式，感觉上可以和 Sex 扯上点关系  \n",
    "2. Age 中有 NaN，需要处理一下，同时 Age 是浮点值  \n",
    "3. SibSp 和 Parch 为整数  \n",
    "4. Ticket 看起来没什么规律，和其他属性也没什么显而易见的关联，drop 掉  \n",
    "5. Cabin 有可能是空值，看起来只是一串字符串，形式应该是 \\[CabinPrefix\\]\\[CabinNumber\\]    \n",
    "\n",
    "直观上得到的结论有这些，接下来，让我们用代码做更进一步的验证  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = = = = = = = = = = = = Check is data contain nan value = = = = = = = = = = = = = = = = = = = =\n",
      "Columns contain nan value:  ['Age', 'Cabin', 'Embarked']\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  PassengerId\n",
      "300    1\n",
      "448    1\n",
      "438    1\n",
      "219    1\n",
      "116    1\n",
      "564    1\n",
      "703    1\n",
      "214    1\n",
      "562    1\n",
      "670    1\n",
      "684    1\n",
      "709    1\n",
      "295    1\n",
      "117    1\n",
      "445    1\n",
      "435    1\n",
      "347    1\n",
      "151    1\n",
      "306    1\n",
      "774    1\n",
      "Name: PassengerId, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Survived\n",
      "1    342\n",
      "0    549\n",
      "Name: Survived, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Pclass\n",
      "3    491\n",
      "2    184\n",
      "1    216\n",
      "Name: Pclass, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Name\n",
      "Renouf, Mrs. Peter Henry (Lillian Jefferys)            1\n",
      "Buss, Miss. Kate                                       1\n",
      "Turja, Miss. Anna Sofia                                1\n",
      "Abbott, Mrs. Stanton (Rosa Hunt)                       1\n",
      "Alhomaki, Mr. Ilmari Rudolf                            1\n",
      "Stankovic, Mr. Ivan                                    1\n",
      "Jensen, Mr. Svend Lauritz                              1\n",
      "Hirvonen, Miss. Hildur E                               1\n",
      "Chaffee, Mr. Herbert Fuller                            1\n",
      "Hamalainen, Master. Viljo                              1\n",
      "Hoyt, Mrs. Frederick Maxfield (Jane Anne Forby)        1\n",
      "Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)          1\n",
      "Johanson, Mr. Jakob Alfred                             1\n",
      "Bowen, Mr. David John \"Dai\"                            1\n",
      "Abelson, Mrs. Samuel (Hannah Wizosky)                  1\n",
      "Dean, Mr. Bertram Frank                                1\n",
      "Swift, Mrs. Frederick Joel (Margaret Welles Barron)    1\n",
      "Andersen-Jensen, Miss. Carla Christine Nielsine        1\n",
      "Mannion, Miss. Margareth                               1\n",
      "Wheadon, Mr. Edward H                                  1\n",
      "Name: Name, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Age\n",
      "44.0     9\n",
      "65.0     3\n",
      "16.0    17\n",
      "70.0     2\n",
      "33.0    15\n",
      "2.0     10\n",
      "30.0    25\n",
      "24.0    30\n",
      "53.0     1\n",
      "42.0    13\n",
      "45.5     2\n",
      "20.0    15\n",
      "5.0      4\n",
      "25.0    23\n",
      "48.0     9\n",
      "38.0    11\n",
      "46.0     3\n",
      "59.0     2\n",
      "3.0      6\n",
      "27.0    18\n",
      "Name: Age, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  SibSp\n",
      "3     16\n",
      "5      5\n",
      "1    209\n",
      "4     18\n",
      "0    608\n",
      "2     28\n",
      "8      7\n",
      "Name: SibSp, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Parch\n",
      "1    118\n",
      "2     80\n",
      "4      4\n",
      "0    678\n",
      "6      1\n",
      "3      5\n",
      "5      5\n",
      "Name: Parch, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Ticket\n",
      "244270        1\n",
      "PC 17477      2\n",
      "364849        2\n",
      "382651        1\n",
      "111369        1\n",
      "2908          2\n",
      "113800        1\n",
      "4135          1\n",
      "28664         1\n",
      "PC 17760      3\n",
      "371110        3\n",
      "350417        1\n",
      "36209         1\n",
      "14311         1\n",
      "C 17369       1\n",
      "A./5. 2152    1\n",
      "392096        2\n",
      "19988         1\n",
      "2623          1\n",
      "C.A. 24580    1\n",
      "Name: Ticket, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Fare\n",
      "19.5000      2\n",
      "78.2667      2\n",
      "9.8458       1\n",
      "50.0000      1\n",
      "8.0500      43\n",
      "7.7875       1\n",
      "76.7292      3\n",
      "7.7417       1\n",
      "57.9792      2\n",
      "263.0000     4\n",
      "8.6542       1\n",
      "21.0750      4\n",
      "12.2875      1\n",
      "69.5500      7\n",
      "49.5000      1\n",
      "7.1417       1\n",
      "79.6500      3\n",
      "7.8000       1\n",
      "9.4833       1\n",
      "14.4542      7\n",
      "Name: Fare, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Cabin\n",
      "D9             1\n",
      "D21            1\n",
      "B96 B98        4\n",
      "C50            1\n",
      "E77            1\n",
      "A20            1\n",
      "C52            2\n",
      "B50            1\n",
      "C126           2\n",
      "C23 C25 C27    4\n",
      "D33            2\n",
      "A14            1\n",
      "F38            1\n",
      "C22 C26        3\n",
      "A32            1\n",
      "F33            3\n",
      "E33            2\n",
      "D56            1\n",
      "B22            2\n",
      "G6             4\n",
      "Name: Cabin, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "Value Counts Of  Embarked\n",
      "Q     77\n",
      "S    644\n",
      "C    168\n",
      "Name: Embarked, dtype: int64\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n"
     ]
    }
   ],
   "source": [
    "print('= ' * 20 + 'Check is data contain nan value' + ' =' * 20)\n",
    "def get_contain_nan_columns(data):\n",
    "    return [column for column in data.columns if data[column].isna().any()]\n",
    "columns_contain_nan = get_contain_nan_columns(data_train)\n",
    "print('Columns contain nan value: ', columns_contain_nan)\n",
    "print('= = ' * 20)\n",
    "def print_columns_value_counts(data):\n",
    "    for column in data.columns:\n",
    "        value_counts = data_train[column].value_counts(dropna=True)\n",
    "        print('Value Counts Of ', column)\n",
    "        print(value_counts.sample(value_counts.shape[0] if value_counts.shape[0] < 20 else 20))\n",
    "        print('= = ' * 20)\n",
    "print_columns_value_counts(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0\n",
      " 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 1 1 1 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "data_train = pd.read_csv('../input/train.csv')\n",
    "data_test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "# for column in X_train.columns:\n",
    "#     print(column, X_train[column].unique())\n",
    "# categorical_columns = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "def convert_sex_to_numerical(sex): \n",
    "    dic = {'male': 0, 'female': 1}\n",
    "    return dic.get(sex, None)\n",
    "\n",
    "def convert_cabin_to_numerical(cabin):\n",
    "    import re\n",
    "    dic = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}\n",
    "    pat = re.compile(r'(\\w)\\d+')\n",
    "    if pd.isna(cabin): return cabin\n",
    "    prefix = re.findall(pat, cabin)\n",
    "    if len(prefix):\n",
    "        return dic[prefix[0]]\n",
    "\n",
    "def convert_embarked_to_numerical(embarked):\n",
    "    dic = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    return dic.get(embarked, None)\n",
    "\n",
    "def process_trainning_data(data):\n",
    "    X = data.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "    X['FamilySize'] = X['SibSp'] + X['Parch']\n",
    "    X = X.drop(['SibSp', 'Parch'], axis=1)\n",
    "    X.Sex = X.Sex.apply(convert_sex_to_numerical)\n",
    "    X.Cabin = X.Cabin.apply(convert_cabin_to_numerical)\n",
    "    X.Embarked = X.Embarked.apply(convert_embarked_to_numerical)\n",
    "    return X\n",
    "\n",
    "\n",
    "y_train = data_train.Survived\n",
    "X_train = process_trainning_data(data_train)\n",
    "X_train.drop(['Survived'], axis=1, inplace=True)\n",
    "imputer = Imputer()\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = process_trainning_data(data_test)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "print(prediction)\n",
    "first_submission = pd.DataFrame({\n",
    "    \"PassengerId\": data_test[\"PassengerId\"],\n",
    "    \"Survived\": prediction\n",
    "})\n",
    "first_submission.to_csv('first_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
